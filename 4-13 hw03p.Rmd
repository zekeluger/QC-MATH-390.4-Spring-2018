---
title: "HW03p"
author: "[Your Name Goes Here]"
date: "April 13, 2018"
output: pdf_document
---

```{r setup, cache = F}
knitr::opts_chunk$set(error = TRUE) #this allows errors to be printed into the PDF
```

1. Load pacakge `ggplot2` below using `pacman`.

```{r}
library(pacman)
pacman::p_load(ggplot2)
```

The dataset `diamonds` is in the namespace now as it was loaded with the `ggplot2` package. Run the following code and write about the dataset below.

```{r}
?diamonds
str(diamonds)
```

What is $n$, $p$, what do the features mean, what is the most likely response metric and why?

***TO-DO
# It's a dataset about a sample of diamonds, their price, size, weight, and quality measures- cut, color, and clarity. n = 53940 observations of 10 variables, though I'd call p = 8 because I'm not including the response variable, and depth is a function of the size variables. This dataset was probably generated in a business setting, where price is the most important variable to predict, thus I expect price is the response metric.

Regardless of what you wrote above, the variable `price` will be the response variable going forward. 

Use `ggplot` to look at the univariate distributions of *all* predictors. Make sure you handle categorical predictors differently from continuous predictors.

```{r}
#TO-DO

for(x_var in colnames(diamonds)[-7]) {
     c = x_var
     if(all(class(diamonds[[c]]) == "numeric")) {
          var_plots = ggplot(diamonds, aes_string(x_var)) + 
               geom_histogram(bins = 100) 
     } else {
          var_plots = ggplot(diamonds, aes_string(x_var)) + 
               geom_bar()
     }
     plot(var_plots)
}
```

Use `ggplot` to look at the bivariate distributions of the response versus *all* predictors. Make sure you handle categorical predictors differently from continuous predictors. This time employ a for loop when an logic that handles the predictor type.

```{r}
#TO-DO
for(x_var in colnames(diamonds)[-c(2:4,7)]) {
     var_plots = ggplot(diamonds, aes_string(x = x_var, y = "price")) + 
          geom_point()
     plot(var_plots)
}
for(x_var in colnames(diamonds)[2:4]) {
     var_plots = ggplot(diamonds, aes_string(x = x_var, y = "price")) + 
          geom_boxplot()
     plot(var_plots)
}
```

Does depth appear to be mostly independent of price?

**TO-DO
# It appears independent in mean, but not in variance. Depth varies more when price is lower.

Look at depth vs price by predictors cut (using faceting) and color (via different colors).

```{r}
#TO-DO
ggplot(diamonds, aes(x = depth, y = price)) + 
     geom_point(aes(col = color)) +
     facet_grid(cut ~ .)
```


Does diamond color appear to be independent of diamond depth?

**TO-DO
# Yes, the color seems to be evenly mixed width-wise in all graphs.

Does diamond cut appear to be independent of diamond depth?

**TO-DO
# No, diamond depth seems to vary more for lower-quality cuts.

Do these plots allow you to assess well if diamond cut is independent of diamond price? Yes / no

**TO-DO
# Not really, the plot is too dense to determine if the density is greater higher on the y-axis (price) for the various facets (cut).

We never discussed in class bivariate plotting if both variables were categorical. Use the geometry "jitter" to visualize color vs clarity. visualize price using different colors. Use a small sized dot.

```{r}
#TO-DO
ggplot(diamonds, aes(color, y = clarity)) +
     geom_jitter(aes(col = price, shape = "."))
sample_5000 = sample(1:53940, 5000)
ggplot(diamonds[sample_5000,], aes(color, y = clarity)) +
     geom_jitter(aes(col = price, shape = "."))
     
```

Does diamond clarity appear to be mostly independent of diamond color?

**TO-DO
# Yes, but it's hard to pick up trends from this graph because it's hard to compare categories with different numbers of occurences. It would be easier to see on overlapping bar graphs subset by color or clarity, or by faceting by color or clarity.

2. Use `lm` to run a least squares linear regression using depth to explain price. 

```{r}
#TO-DO
dvp = lm(price ~ depth, diamonds)
summary(dvp)
```

What is $b$, $R^2$ and the RMSE? What was the standard error of price originally? 


```{r}
#TO-DO
list(
     "b = " = as.numeric(dvp$coefficients[2]),
     "R^2 = " = summary(dvp)$r.squared,
     "RMSE = " = summary(dvp)$sigma,
     "SD[price] = " = sd(diamonds$price)
)
ggplot(diamonds, aes(x = depth, y = price)) + 
          geom_point()
```

Are these metrics expected given the appropriate or relevant visualization(s) above?

**TO-DO
# These seem appropriate. The coefficient of ~-30 is approximately = 0 since the regression line will only vary by $1200 across the entire range of depths, which is very small compared to the total range of $20,000 in price. The R^2 is small since depth explains very little of the variance in price. And the RMSE value is almost exactly the same as the null model standard deviation because we have explained none of the variance in price.

Use `lm` to run a least squares linear regression using carat to explain price. 

```{r}
#TO-DO
caratvprice = lm(price ~ carat, diamonds)
summary(caratvprice)
```

What is $b$, $R^2$ and the RMSE? What was the standard error of price originally? 

```{r}
#TO-DO
list(
     "b = " = as.numeric(caratvprice$coefficients[2]),
     "R^2 = " = summary(caratvprice)$r.squared,
     "RMSE = " = summary(caratvprice)$sigma,
     "SD[price] = " = sd(diamonds$price)
)
ggplot(diamonds, aes(x = carat, y = price)) + 
          geom_point()
```

Are these metrics expected given the appropriate or relevant visualization(s) above?

**TO-DO
# These metrics also seem appropriate. The coefficient of ~8000 makes sense given that the weight of the diamond and its price seem to be highly correlated, both on the graph, and intuitively. The R^2 is small since depth explains very little of the variance in price. And the RMSE value is about 39% of the pre-regression standard error because we have explained a significant amount of the variance in price using the carat variable.


3. Use `lm` to run a least squares anova model using color to explain price. 

```{r}
#TO-DO
colormod = lm(price ~ as.character(color), diamonds)
names(colormod$coefficients) = c("(Intercept)", "color E", "color F", "color G", "color H", "color I", "color J")
colormod
summary(colormod)
```

What is $b$, $R^2$ and the RMSE? What was the standard error of price originally? 

```{r}
#TO-DO
list(
     "b = " = coef(colormod),
     "R^2 = " = summary(colormod)$r.squared,
     "RMSE = " = summary(colormod)$sigma,
     "SD[price] = " = sd(diamonds$price)
)
ggplot(diamonds, aes(x = color, y = price)) + 
     geom_boxplot()
```

Are these metrics expected given the appropriate or relevant visualization(s) above?

**TO-DO
# Yes, given the visualization above, the metrics are appropriate. The intercept (the mean for D) is a little bit above the median displayed on the box plot for D. The coefficient for E shows that E's mean is slightly below D's, and the rest of the coefficients show the other colors each have a progressively higher mean.
# However, this doesn't make sense based on intuition about the price~color relationship. Since D is the best quality color, shouldn't it be sold at the highest prices? The only explanation I've come up with is that perhaps it's so difficult to find diamonds with a high color-quality that the few they can find are small or less valuable in some other metric. And I think I've found some evidence below. There are many more large poor-color diamonds than large good-color diamonds. Also, when you account for other variables such as carat in the regression, the coefficients for color, cut, and clarity actually switch from worse-quality diamonds giving higher prices to better-quality diamonds giving higher prices.

```{r}
ggplot(diamonds, aes(x = color, y = carat)) + 
     geom_boxplot()
lm(price ~ carat + as.character(cut) + as.character(color) + as.character(clarity) + depth + table + x + y + z, diamonds)
```

#### I AM UP TO HERE!!!!
#### I AM UP TO HERE!!!!
#### I AM UP TO HERE!!!!
#### I AM UP TO HERE!!!!
#### I AM UP TO HERE!!!!
#### I AM UP TO HERE!!!!
#### I AM UP TO HERE!!!!



Our model only included one feature - why are there more than two estimates in $b$?

**TO-DO
# There are more than two estimates because that's how linear models deal with categorical variables. The first estimate in b gives the mean for color level "D"; this is the intecept. The second gives the estimate for the amount the mean for "E" differs from that of "D". The third gives the amount the estimate for "F" differs from "D", and on until the last one which gives the amount "J" differs from "D".

Verify that the least squares linear model fit gives the sample averages of each price given color combination. Make sure to factor in the intercept here.

```{r}
#TO-DO
q = sort(unique(diamonds$color))
for(i in q) {
     color_means[i] = mean(diamonds$price[diamonds$color == i])
}

all.equal(as.numeric(color_means[1]), as.numeric(colormod$coefficients[1]))
j = 2
for(i in q[-1]) {
     print(all.equal(as.numeric(color_means[i]), as.numeric(colormod$coefficients[j] + colormod$coefficients[1])))
     j = j+1
}
```

Fit a new model without the intercept and verify the sample averages of each colors' prices *directly* from the entries of vector $b$.

```{r}
#TO-DO
nointecept = lm(price ~ 0 + color, diamonds)
nointecept
```

What would extrapolation look like in this model? We never covered this in class explicitly.

**TO-DO
# I think extrapolation in this model would be to assert that if there were a class "C", it would have an average price lower than class "D", and likewise if there were a class "K", it would have a higher average price than class "J".

4. Use `lm` to run a least squares linear regression using all available features to explain diamond price. 

```{r}
#TO-DO
fullmod = lm(price ~ carat + as.character(cut) + as.character(color) + as.character(clarity) + depth + table + x + y + z, diamonds)
names(fullmod$coefficients) = c("(Intercept)", "carat", "cut Good", "cut Ideal", "cut Premium", "cut Very Good", "color E", "color F", "color G", "color H", "color I", "color J", "clarity IF", "clarity SI1", "clarity SI2", "clarity VS1", "clarity VS2", "clarity VVS1", "clarity VVS2", "depth", "table", "x", "y", "z")
fullmod
```

What is $b$, $R^2$ and the RMSE? Also - provide an approximate 95% interval for predictions using the empirical rule. 

```{r}
#TO-DO
list(
     "b = " = coef(fullmod),
     "R^2 = " = summary(fullmod)$r.squared,
     "RMSE = " = summary(fullmod)$sigma,
     "CI, 95% = " = noquote(paste("±", 2 * summary(fullmod)$sigma))
)
```

Interpret all entries in the vector $b$.

**TO-DO
# The intercept is the expected value for a 0 carat diamond with a Fair cut, of color D, of clarity I1, depth 0, table 0, and x, y, and z lengths of 0. The carat coefficient measures how much the price goes up on average for each 1 carat increase in diamond weight. The coefficients for the other numerical characteristics, depth, table, and x, y, and z lengths, go up on average by the amount of their coefficient for each 1 unit increase. cut Good says how much higher the average price of a diamond with a Good cut is than the average for a diamond with a Fair cut. All the other ordinal characteristics work the same way.


Are these metrics expected given the appropriate or relevant visualization(s) above? Can you tell from the visualizations?

**TO-DO
# I don't feel like I can tell from the visualizations above how good a fit the linear model is. I think I'd need to see a 10-dimensional plot of our features against price, and see if the points were close to the hyperplane. Unfortunately, as a human and 3-4 dimensional being, I am limited in this capacity :(


Comment on why $R^2$ is high. Think theoretically about diamonds and what you know about them.

**TO-DO
# Since diamonds are priced by people based on the characteristics described in our feature set, they should explain most of the variance in price.


Do you think you overfit? Comment on why or why not but do not do any numerical testing or coding.

**TO-DO
# I don't think we've overfit because we only have 10 degrees of freedom explaining a dataset of ~50,000 observations.


Create a visualization that shows the "original residuals" (i.e. the prices minus the average price) and the model residuals.

```{r}
#TO-DO
residuals = diamonds$price - predict(fullmod, diamonds)
ggplot(diamonds, aes(x = price, y = residuals)) +
     geom_point()
```


5. Reference your visualizations above. Does price vs. carat appear linear?

```{r}
ggplot(diamonds, aes(x = carat, y = price)) + 
          geom_point()
```

** TO-DO
# Price vs. carat doesn't quite appear linear as there appears to be a slight curve upwards in the graph. However, the curve is slight, so a linear model should do fine.

Upgrade your model in #4 to use one polynomial term for carat.

```{r}
#TO-DO
square_carat = lm(price ~ poly(carat, 2) + as.character(cut) + as.character(color) + as.character(clarity) + depth + table + x + y + z, diamonds)
names(square_carat$coefficients) = c("(Intercept)", "carat", "carat^2", "cut Good", "cut Ideal", "cut Premium", "cut Very Good", "color E", "color F", "color G", "color H", "color I", "color J", "clarity IF", "clarity SI1", "clarity SI2", "clarity VS1", "clarity VS2", "clarity VVS1", "clarity VVS2", "depth", "table", "x", "y", "z")
square_carat
```

What is $b$, $R^2$ and the RMSE? 

```{r}
#TO-DO
list(
     "b = " = coef(square_carat),
     "R^2 = " = summary(square_carat)$r.squared,
     "RMSE = " = summary(square_carat)$sigma
)
```

Interpret each element in $b$ just like previously. You can copy most of the text from the previous question but be careful. There is one tricky thing to explain.

**TO-DO
# It's the same as above, but here, the carat^2 coefficient measures how much the price goes up on average for each 1 SQUARE increase in carat. i.e. the average increase in price as carat goes from 1 to 4, or 4 to 9, or 9 to 16.

Is this an improvement over the model in #4? Yes/no and why.

**TO-DO
# This is a slight but significant improvement over our model in #4, as R^2 has increased to .9215 from .9198, and RMSE has decreased from 1130 to 1118. It's significant because our p+1 still does not approach n. This model is probably a signficant improvement because the graph of price vs. carat looks slightly parabolic.

Define a function $g$ that makes predictions given a vector of the same features in $\mathbb{D}$.

```{r}
#TO-DO
sqcarat_predict = function(data) {
     predict(square_carat, data)
}
sqcarat_predict(diamonds[1, ])
```

6. Use `lm` to run a least squares linear regression using a polynomial of color of degree 2 to explain price.  

```{r}
#TO-DO
color_poly = lm(price ~ poly(color, 2), diamonds)
```

Why did this throw an error?

**TO-DO
# It throws an error because color is not a numeric value, therefore it cannot be squared. i.e. what's "Fair"^2?


7. Redo the model fit in #4 without using `lm` but using the matrix algebra we learned about in class. This is hard and requires many lines, but it's all in the notes.

```{r}
#TO-DO
diamonds_mm = model.matrix(price ~ carat + as.character(cut) + as.character(color) + as.character(clarity) + depth + table + x + y + z, diamonds)
colnames(diamonds_mm) = c("(Intercept)", "carat", "cut Good", "cut Ideal", "cut Premium", "cut Very Good", "color E", "color F", "color G", "color H", "color I", "color J", "clarity IF", "clarity SI1", "clarity SI2", "clarity VS1", "clarity VS2", "clarity VVS1", "clarity VVS2", "depth", "table", "x", "y", "z")
X = as.matrix(diamonds_mm)
y = diamonds$price
b = solve(t(X) %*% X) %*% t(X) %*% y
b
```

What is $b$, $R^2$ and the RMSE? 

```{r}
#TO-DO
# R^2:
SSE_0 = sum((y-mean(y))^2)
yhat = X %*% b
e = y-yhat
SSE = sum((y-yhat)^2)
r_squared = (SSE_0 - SSE) / SSE_0

# RMSE:
p = ncol(diamonds_mm) - 1
n = nrow(diamonds_mm)
MSE = (1/(n-(p+1))) * SSE
RMSE = sqrt(MSE)

list(
     "b = " = b,
     "R^2 = " = r_squared,
     "RMSE = " = RMSE
)
```

Are they the same as in #4?

**TO-DO
# YES!

Redo the model fit using matrix algebra by projecting onto an orthonormal basis for the predictor space $Q$ and the Gram-Schmidt "remainder" matrix $R$. Formulas are in the notes. Verify $b$ is the same.

```{r}
#TO-DO
qrx = qr(X)
Q = qr.Q(qrx)
R = qr.R(qrx)

b = solve(R) %*% t(Q) %*% y
b
```


Generate the vectors $\hat{y}$, $e$ and the hat matrix $H$.

```{r}
#TO-DO

yhat = as.numeric(X %*% b)
e = y-yhat

# I think it's just this, but I'm not sure. Beware before running!:
# H = Q %*% t(Q)
# maybe_yhat = H[1:6, ] %*% y

head(yhat)
head(e)
#H[1:20, 1:6]
#maybe_yhat
```

In one line each, verify that 
(a) $\hat{y}$ and $e$ sum to the vector $y$ (the prices in the original dataframe), 
(b) $\hat{y}$ and $e$ are orthogonal 
(c) $e$ projected onto the column space of $X$ gets annhilated, 
(d) $\hat{y}$ projected onto the column space of $X$ is unaffected, 
(e) $\hat{y}$ projected onto the orthogonal complement of the column space of $X$ is annhilated
(f) the sum of squares residuals plus the sum of squares model equal the original (total) sum of squares

```{r}
#TO-DO
# (a) $\hat{y}$ and $e$ sum to the vector $y$ (the prices in the original dataframe), 

yhat_plus_e = yhat + e
all.equal(yhat_plus_e, y)

# (b) $\hat{y}$ and $e$ are orthogonal 
yhat %*% e

yhat_dot_e = as.numeric(yhat %*% e)
yhat_dot_e
all.equal(yhat_dot_e, 0)
# I think this comes out to not exactly zero because of numerical error?
########################################################################
#???????????????????????????????????????????????????????????????????????

# (c) $e$ projected onto the column space of $X$ gets annhilated, 

# all.equal(H %*% e, 0)

# (d) $\hat{y}$ projected onto the column space of $X$ is unaffected, 

# all.equal(H %*% yhat, yhat)

# (e) $\hat{y}$ projected onto the orthogonal complement of the column space of $X$ is annhilated

# I = diag(53940)
# all.equal((I-H) %*% yhat, 0)

# (f) the sum of squares residuals plus the sum of squares model equal the original (total) sum of squares

# SSE? + SSR = SST
ybar = mean(y)
SSE = sum((y-yhat)^2)
SSM = sum((yhat-ybar)^2)
SST = sum((y-ybar)^2)
all.equal(SSE + SSM, SST)
```

8. Fit a linear least squares model for price using all interactions and also 5-degree polynomials for all continuous predictors.

```{r}
#TO-DO

poly5_mod = lm(price ~ poly(carat, 5) + as.character(cut) + as.character(color) + as.character(clarity) + poly(depth, 5) + poly(table, 5) + poly(x, 5) + poly(y, 5) + poly(z, 5), diamonds)
poly5_mod
#summary(poly5_mod)
```

Report $R^2$, RMSE, the standard error of the residuals ($s_e$) but you do not need to report $b$.

```{r}
#TO-DO
n = nrow(diamonds)
p = length(poly5_mod$coefficients)
list(
     "R^2 = " = summary(poly5_mod)$r.squared,
     "RMSE = " = summary(poly5_mod)$sigma,
     "s_e = " = sqrt((1/(n-(p+1)))*sum((summary(poly5_mod)$residuals)^2))
)
```

Create an illustration of $y$ vs. $\hat{y}$.

```{r}
#TO-DO
yhat_poly5 = predict(poly5_mod, diamonds)
dummy_frame = data.frame(y = y, yhat_poly5 = yhat_poly5)
ggplot(dummy_frame, aes(x = yhat_poly5, y = y)) + 
          geom_point()

```

How many diamonds have predictions that are wrong by \$1,000 or more ?

```{r}
#TO-DO
residuals_poly5 = summary(poly5_mod)$residuals
big_error_list = residuals_poly5[ residuals_poly5 > 1000 ]
length(big_error_list)
```

$R^2$ now is very high and very impressive. But is RMSE impressive? Think like someone who is actually using this model to e.g. purchase diamonds.

**TO-DO
# Using the Empirical Rule, our RMSE gives us a 95% confidence window of about $4000 (±$2000) around our price estimate. If you're looking to make a bid on a diamond or wtv people do with this data, you probably want more confidence that you're getting a good deal, which means a smaller CI.

What is the degrees of freedom in this model?

```{r}
#TO-DO
length(poly5_mod$coefficients)
```

Do you think $g$ is close to $h^*$ in this model? Yes / no and why?

**TO-DO
# Yes, I do think it's close. With 50,000 observations, there will be little estimation error in the 48 parameters.

Do you think $g$ is close to $f$ in this model? Yes / no and why?

**TO-DO
# Yeah, it's probably pretty close because it has an R^2 value of .93. That means the best possible model using these features could only, at best, explain 7% more variance, and some of that 7% is probably just due to ignorance (i.e. the whims of diamond pricers).

What more degrees of freedom can you add to this model to make $g$ closer to $f$?

** TO-DO
# I could add interaction terms.

Even if you allowed for so much expressivity in $\mathcal{H}$ that $f$ was an element in it, there would still be error due to ignorance of relevant information that you haven't measured. What information do you think can help? This is not a data science question - you have to think like someone who sells diamonds.

** TO-DO
# The fluctuation of the local or international markets for diamonds would probably explain some more of the variance. Also other trends in diamonds might account for some more of the variance. Also data on sales at the individual diamond sellers probably affects prices.

9. Validate the model in #8 by reserving 10% of $\mathbb{D}$ as test data. Report oos standard error of the residuals

```{r}
#TO-DO
n = nrow(diamonds)
k = 5

y = diamonds$price
test_indices = sample(1:n, n*(1/k))
train_indices = setdiff(1:n, test_indices)
diamonds_train = diamonds[train_indices, ]
diamonds_test = diamonds[test_indices, ]

test_poly5_mod = lm(price ~ poly(carat, 5) + as.character(cut) + as.character(color) + as.character(clarity) + poly(depth, 5) + poly(table, 5) + poly(x, 5) + poly(y, 5) + poly(z, 5), diamonds_train)
yhat_test = predict(test_poly5_mod, diamonds_test)
sd(yhat_test - y[test_indices])
```

Compare the oos standard error of the residuals to the standard error of the residuals you got in #8 (i.e. the in-sample estimate). Do you think there's overfitting?

** TO-DO
# The OOS Se of the residuals is usually about the same as the in-sample estimate- a little more than 1000, but occasionally balloons up to several million.

Extra-credit: validate the model via cross validation.

```{r}
#TO-DO if you want extra credit

n = nrow(diamonds)
k = 5
y = diamonds$price
std_errors = numeric(0)

for (i in 1:50) {
     test_indices = sample(1:n, n*(1/k))
     train_indices = setdiff(1:n, test_indices)
     diamonds_train = diamonds[train_indices, ]
     diamonds_test = diamonds[test_indices, ]
     
     test_poly5_mod = lm(price ~ poly(carat, 5) + as.character(cut) + 
          as.character(color) + as.character(clarity) + 
          poly(depth, 5) + poly(table, 5) + poly(x, 5) + 
          poly(y, 5) + poly(z, 5), diamonds_train)
     yhat_test = predict(test_poly5_mod, diamonds_test)
     std_errors[i] = sd(yhat_test - y[test_indices])
}
options(scipen=2)
sedf = as.data.frame(std_errors)
sedf
#ggplot(std_errors, aes(std_errors)) + geom_histogram()
ggplot(sedf, aes(sedf)) + geom_histogram(binwidth = 10000)
ggplot(sedf, aes(sedf)) + geom_density()
```

Is this result much different than the single validation? And, again, is there overfitting in this model?

** TO-DO
# Yes, depending on which sample happened to go into the test set, the single validation results varied wildly. Most were around 1000, the in-sample s_e, but then there'd be a few that were in the millions- very different.

10. The following code (from plec 14) produces a response that is the result of a linear model of one predictor and random $\epsilon$.

```{r}
rm(list = ls())
set.seed(1003)
n = 100
beta_0 = 1
beta_1 = 5
xmin = 0
xmax = 1
x = runif(n, xmin, xmax)
#best possible model
h_star_x = beta_0 + beta_1 * x

#actual data differs due to information we don't have
epsilon = rnorm(n)
y = h_star_x + epsilon
```

We then add fake predictors. For instance, here is the model with the addition of 2 fake predictors:

```{r}
p_fake = 2
X = matrix(c(x, rnorm(n * p_fake)), ncol = 1 + p_fake)
mod = lm(y ~ X)
```

Using a test set hold out, find the number of fake predictors where you can reliably say "I overfit". Some example code is below that you may want to use:

```{r}
#TO-DO
n = nrow(X)
k = 5

test_indices = sample(1:n, n*(1/k))
train_indices = setdiff(1:n, test_indices)
X_train = as.matrix(X[train_indices, ])
y_train = y[train_indices]
X_test = as.data.frame(X[test_indices, ])
y_test = y[test_indices]

mod = lm(y_train ~ X_train)
y_hat_oos = predict(mod, X_test)

options(scipen=999)
sd(y_hat_oos - y_test)
```



















